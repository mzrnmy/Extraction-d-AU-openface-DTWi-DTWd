{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76cdc3e6",
   "metadata": {},
   "source": [
    "## Extraction des données, Creation de vecteur et Normalisation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daaed15",
   "metadata": {},
   "source": [
    "Ici on extrait avec open face des csv des informations sur chaques participants par frame.\n",
    "Ensuite on trie les csv pour ne prendre que les AUs selectionnée et les transformer en tableaux numpy.\n",
    "Puis enfin on normalise les données de chaques AUs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6139a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "OPENFACE_DIR = Path(r\"C:\\Users\\Ordinateur\\Desktop\\Projet tutoret\\OpenFace_2.2.0_win_x64\\OpenFace_2.2.0_win_x64\")\n",
    "VIDEOS_DIR   = Path(r\"C:\\Users\\Ordinateur\\Desktop\\----------------------Test pipeline----------------------------\\Vidéos\") #mettre le dossier ou se situe les videos des participants \n",
    "CSV_DIR      = VIDEOS_DIR / \"openface_csv\"\n",
    "NUMPY_DIR    = VIDEOS_DIR / \"openface_numpy\"\n",
    "\n",
    "# Création des dossiers si pas existants\n",
    "#CSV_DIR.mkdir(exist_ok=True)\n",
    "#NUMPY_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "AU_COLS = [\n",
    "    \"AU01_r\", \"AU02_r\", \"AU04_r\", \"AU05_r\", \"AU06_r\", \"AU07_r\",\n",
    "    \"AU09_r\", \"AU10_r\", \"AU12_r\", \"AU14_r\", \"AU15_r\", \"AU17_r\",\n",
    "    \"AU20_r\", \"AU23_r\", \"AU25_r\", \"AU26_r\", \"AU45_r\"\n",
    "]\n",
    "\n",
    "# === FONCTION 1 : Extraction des CSV depuis les vidéos ===\n",
    "def extract_openface_features(videos_dir: Path, openface_dir: Path, out_dir: Path):\n",
    "    \"\"\"Extrait les features OpenFace pour toutes les vidéos dans videos_dir.\"\"\"\n",
    "    extractor = openface_dir / \"FeatureExtraction.exe\"\n",
    "    if not extractor.exists():\n",
    "        raise FileNotFoundError(f\"{extractor} introuvable.\")\n",
    "\n",
    "    for i, vid in enumerate(videos_dir.iterdir()):\n",
    "        if vid.suffix.lower() in {'.mov', '.mp4', '.avi'}:\n",
    "            output_subdir = out_dir / f\"participant_{i+1}\"\n",
    "            output_subdir.mkdir(exist_ok=True)\n",
    "            print(f\"[OpenFace] Extraction de {vid.name} → {output_subdir.name}\")\n",
    "            subprocess.run(\n",
    "                [\n",
    "                    str(extractor),\n",
    "                    \"-f\", str(vid),\n",
    "                    \"-out_dir\", str(output_subdir)\n",
    "                ],\n",
    "                cwd=str(openface_dir),\n",
    "                stdout=subprocess.DEVNULL,\n",
    "                stderr=subprocess.DEVNULL,\n",
    "                check=True\n",
    "            )\n",
    "\n",
    "# === FONCTION 2 : Conversion CSV → Tableaux numpy ===\n",
    "def convert_csvs_to_numpy(csv_dir: Path, robot_csv: Path, au_cols: list[str], numpy_dir: Path):\n",
    "    \"\"\"Charge les CSV, extrait les colonnes AU, sauvegarde les tableaux numpy.\"\"\"\n",
    "\n",
    "    def load_and_clean(filepath: Path) -> np.ndarray:\n",
    "        df = pd.read_csv(filepath)\n",
    "        df.columns = [re.sub(r\"\\s+\", \"\", col) for col in df.columns]\n",
    "        missing = set(au_cols) - set(df.columns)\n",
    "        if missing:\n",
    "            print(f\"⚠ Colonnes manquantes dans {filepath.name} : {missing}\")\n",
    "        return df.loc[:, au_cols].values\n",
    "\n",
    "    # Charger le robot\n",
    "    robot_data = load_and_clean(robot_csv)\n",
    "    np.save(numpy_dir / \"robot.npy\", robot_data)\n",
    "    \n",
    "    # Charger chaque participant\n",
    "    for part_dir in csv_dir.iterdir():\n",
    "        if part_dir.is_dir():\n",
    "            for file in part_dir.glob(\"*.csv\"):\n",
    "                participant_name = part_dir.name\n",
    "                data = load_and_clean(file)\n",
    "                np.save(numpy_dir / f\"{participant_name}.npy\", data)\n",
    "\n",
    "# === FONCTION 3 : Normalisation des tableaux numpy ===\n",
    "def normalize_numpy_arrays(numpy_dir: Path):\n",
    "    \"\"\"Charge les .npy, les normalise, et les écrase.\"\"\"\n",
    "\n",
    "    def z_normalize(X: np.ndarray, eps: float = 1e-8) -> np.ndarray:\n",
    "        mu  = X.mean(axis=0, keepdims=True)\n",
    "        std = X.std(axis=0, keepdims=True)\n",
    "        std[std < eps] = 1.0\n",
    "        return (X - mu) / std\n",
    "\n",
    "    for file in numpy_dir.glob(\"*.npy\"):\n",
    "        print(f\"Normalisation de {file.name}\")\n",
    "        data = np.load(file)\n",
    "        data_norm = z_normalize(data)\n",
    "        np.save(file, data_norm)\n",
    "\n",
    "# === PIPELINE COMPLÈTE (exemple d'appel) ===\n",
    "def run_data_preparation():\n",
    "    extract_openface_features(VIDEOS_DIR, OPENFACE_DIR, CSV_DIR)\n",
    "    convert_csvs_to_numpy(CSV_DIR, Path(r\"C:\\Users\\Ordinateur\\Desktop\\Test pipeline\\Robot_csv\\WhatsApp Video 2025-04-30 at 12.37.38.csv\"), AU_COLS, NUMPY_DIR)\n",
    "    normalize_numpy_arrays(NUMPY_DIR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8c01f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OpenFace] Extraction de essai-AVEC-imitation.avi → participant_1\n",
      "[OpenFace] Extraction de essai-SANS-imitation.avi → participant_2\n",
      "Normalisation de participant_1.npy\n",
      "Normalisation de participant_2.npy\n",
      "Normalisation de robot.npy\n"
     ]
    }
   ],
   "source": [
    "run_data_preparation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d576d96",
   "metadata": {},
   "source": [
    "# DTWI et DTWD causales \n",
    "On utilise la bibliothèque dtaidistance pour performer DTWi et DTWd au tableau d'au de chaque participants par apport au robot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a84e0a6",
   "metadata": {},
   "source": [
    "Dans les DTW classique toutes les correspondances sont acceptées, même si l'humain agit avant le robot, mais cela ne correspond pas à notre définition de l'imitation (puisque le robot doit agir en premier)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a62e87f",
   "metadata": {},
   "source": [
    "Pour respecter la logique d’imitation, on filtre nos données pour que dans l'algorithme on mesure la similiarité que si les données des participants précedes celles du rebot dans lanalyse. Concretement on garde uniquement les paires (i, j) du chemin optimal où j ≥ i."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea642128",
   "metadata": {},
   "source": [
    "Ensuite, pour éviter de prendre en compte des réponses trop tardives, on ajoute aussi une contrainte de fenêtre temporelle.On filtre aussi les paires (i, j) pour garder uniquement celles où le décalage est inférieur ou égal à un certain nombre de frames (par exemple 30 frames). Cela nous permet de ne valider l'imitation que si elle se produit rapidement après l'action du robot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adea9bf",
   "metadata": {},
   "source": [
    "LEs mesures: \n",
    "- score: Rapport DTWD / (DTWI + ε). Il donne une idée de combien la séquence globale (DTWD) est proche par rapport à la somme indépendante (DTWI). Plus il est petit, plus il y a une vraie coordination globale.\n",
    "- Distance DTW dépendante, mais en filtrant uniquement les appariements causaux (le participant réagit après ou très peu après le robot, avec un délai ≤ 30 frames). Plus c’est faible, plus l’imitation causale est forte.\n",
    "- Distance DTW indépendante en version causale (chaque AU évaluée individuellement, mais toujours en respectant la causalité)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d376e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from dtaidistance import dtw, dtw_ndim\n",
    "\n",
    "def full_causal_dtw_analysis(numpy_dir: Path, fps: int = 30, delay_sec: float = 1.0):\n",
    "    \"\"\"\n",
    "    Pipeline complète : calcul DTWD_causal, DTWI_causal, heatmaps, alignements, courbes brutes.\n",
    "    \n",
    "    Args:\n",
    "        numpy_dir (Path): Dossier contenant les .npy normalisés.\n",
    "        fps (int): Images par seconde de la vidéo (défaut = 30).\n",
    "        delay_sec (float): Délai maximum pour l'imitation (en secondes).\n",
    "    \"\"\"\n",
    "    print(\"Chargement des données...\")\n",
    "    robot_array = np.load(numpy_dir / \"robot.npy\")\n",
    "    participant_files = [f for f in numpy_dir.glob(\"*.npy\") if \"robot\" not in f.name]\n",
    "    max_delay_frames = int(delay_sec * fps)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    print(\"Calcul des distances DTW causales...\")\n",
    "    for part_file in participant_files:\n",
    "        part_array = np.load(part_file)\n",
    "\n",
    "        # DTWD causal\n",
    "        path_d = dtw_ndim.warping_path(robot_array, part_array)\n",
    "        valid_pairs_d = [(i, j) for (i, j) in path_d if 0 <= j - i <= max_delay_frames]\n",
    "        dtwd_causal = np.mean([np.linalg.norm(robot_array[i] - part_array[j]) for (i, j) in valid_pairs_d]) if valid_pairs_d else np.nan\n",
    "\n",
    "        # DTWI causal\n",
    "        distances_i = []\n",
    "        for d in range(robot_array.shape[1]):\n",
    "            path_i = dtw.warping_path(robot_array[:, d], part_array[:, d])\n",
    "            valid_pairs_i = [(i, j) for (i, j) in path_i if 0 <= j - i <= max_delay_frames]\n",
    "            if valid_pairs_i:\n",
    "                distances_i.extend([abs(robot_array[i, d] - part_array[j, d]) for (i, j) in valid_pairs_i])\n",
    "        dtwi_causal = np.mean(distances_i) if distances_i else np.nan\n",
    "\n",
    "        # Score causal\n",
    "        score_causal = dtwd_causal / (dtwi_causal + 1e-6) if dtwi_causal else np.nan\n",
    "\n",
    "        results.append({\n",
    "            \"participant\": part_file.stem,\n",
    "            \"DTWD_causal\": dtwd_causal,\n",
    "            \"DTWI_causal\": dtwi_causal,\n",
    "            \"score_causal\": score_causal\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"Résultats calculés :\")\n",
    "    print(results_df)\n",
    "\n",
    "    # --- Graphiques ---\n",
    "    print(\"Génération des graphiques...\")\n",
    "\n",
    "    # Courbes brutes (moyennes des AUs)\n",
    "    robot_mean = robot_array.mean(axis=1)\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(robot_mean, label=\"Robot\", linewidth=2)\n",
    "    for part_file in participant_files:\n",
    "        part_array = np.load(part_file)\n",
    "        plt.plot(part_array.mean(axis=1), label=part_file.stem, linestyle='--')\n",
    "    plt.title(\"Courbes brutes (sans DTW) - Moyenne des AUs par frame\")\n",
    "    plt.xlabel(\"Frames\")\n",
    "    plt.ylabel(\"Intensité normalisée\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Heatmaps\n",
    "    dtwd_values = [0] + results_df[\"DTWD_causal\"].tolist()\n",
    "    dtwi_values = [0] + results_df[\"DTWI_causal\"].tolist()\n",
    "    labels = [\"Robot\"] + results_df[\"participant\"].tolist()\n",
    "\n",
    "    dtwd_matrix = np.full((len(dtwd_values), len(dtwd_values)), np.nan)\n",
    "    dtwi_matrix = np.full((len(dtwi_values), len(dtwi_values)), np.nan)\n",
    "    for i in range(1, len(dtwd_values)):\n",
    "        dtwd_matrix[0, i] = dtwd_values[i]\n",
    "        dtwd_matrix[i, 0] = dtwd_values[i]\n",
    "        dtwi_matrix[0, i] = dtwi_values[i]\n",
    "        dtwi_matrix[i, 0] = dtwi_values[i]\n",
    "\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(dtwd_matrix, annot=True, fmt=\".3f\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(\"Heatmap DTWD_causal\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(dtwi_matrix, annot=True, fmt=\".3f\", cmap=\"Greens\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(\"Heatmap DTWI_causal\")\n",
    "    plt.show()\n",
    "\n",
    "    # Alignements globaux et par AU\n",
    "    for part_file in participant_files:\n",
    "        part_array = np.load(part_file)\n",
    "        participant_name = part_file.stem\n",
    "\n",
    "        # Alignement global DTWD\n",
    "        path = dtw_ndim.warping_path(robot_array, part_array)\n",
    "        valid_pairs = [(i, j) for (i, j) in path if 0 <= j - i <= max_delay_frames]\n",
    "        robot_mean = robot_array.mean(axis=1)\n",
    "        part_mean = part_array.mean(axis=1)\n",
    "\n",
    "        offset = 2.5\n",
    "        plt.figure(figsize=(14,5))\n",
    "        plt.plot(robot_mean, label=\"Robot\", color='red')\n",
    "        plt.plot(part_mean + offset, label=participant_name, color='blue')\n",
    "        for i, j in valid_pairs:\n",
    "            plt.plot([i, j], [robot_mean[i], part_mean[j] + offset], color='gray', alpha=0.5, linewidth=0.6)\n",
    "        plt.title(f\"Alignement DTWD Causal (robot vs {participant_name})\")\n",
    "        plt.xlabel(\"Frames\")\n",
    "        plt.yticks([])\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Alignement par AU (DTWI causal)\n",
    "        n_aus = robot_array.shape[1]\n",
    "        for d in range(n_aus):\n",
    "            robot_seq = robot_array[:, d]\n",
    "            part_seq = part_array[:, d]\n",
    "            path = dtw.warping_path(robot_seq, part_seq)\n",
    "            valid_pairs = [(i, j) for (i, j) in path if 0 <= j - i <= max_delay_frames]\n",
    "\n",
    "            plt.figure(figsize=(14,5))\n",
    "            plt.plot(robot_seq, label=\"Robot\", color='red')\n",
    "            plt.plot(part_seq + offset, label=participant_name, color='blue')\n",
    "            for i, j in valid_pairs:\n",
    "                plt.plot([i, j], [robot_seq[i], part_seq[j] + offset], color='gray', alpha=0.5, linewidth=0.6)\n",
    "            plt.title(f\"Alignement DTWI Causal - AU{d+1} ({participant_name})\")\n",
    "            plt.xlabel(\"Frames\")\n",
    "            plt.yticks([])\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "024ffba0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_causal_dtw_analysis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mfull_causal_dtw_analysis\u001b[49m(numpy_dir\u001b[38;5;241m=\u001b[39mNUMPY_DIR, fps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, delay_sec\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'full_causal_dtw_analysis' is not defined"
     ]
    }
   ],
   "source": [
    "full_causal_dtw_analysis(numpy_dir=NUMPY_DIR, fps=30, delay_sec=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa9c058",
   "metadata": {},
   "source": [
    "## Representation graphiques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820938a9",
   "metadata": {},
   "source": [
    "### Matrice \n",
    "Plus la distance est petite, plus les séquences sont similaires.\n",
    "\n",
    "Si DTWA(Robot, Part1) < DTWA(Robot, Part2), c’est un indice fort d’imitation réussie par le participant 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04eb311",
   "metadata": {},
   "source": [
    "### Alignement global"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9d3013",
   "metadata": {},
   "source": [
    "### Alignement par AUS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d2e9a2",
   "metadata": {},
   "source": [
    "### Moyenne des AUs tab (trace les courbes moyennes des AUs par frame, sans appariement DTW du tout, encore moins filtré.)\n",
    "Si les courbes se ressemblent en forme (pics, plateaux...), c’est un signe d’imitation ou de synchronisation.\n",
    "\n",
    "Si elles sont décalées mais suivent les mêmes motifs, cela peut être corrigé par la DTW.\n",
    "\n",
    "Une courbe très différente (autres pics, autres tendances) = pas d’imitation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b101b03",
   "metadata": {},
   "source": [
    "# Graph pour chaques AUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fff172",
   "metadata": {},
   "source": [
    "L'alignement par Aus pour un participant semble plus pertinent à analyser graphiquement on peux voir si des actions musculaire ont lieux apres celles du robot \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
